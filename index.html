<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Bio-Inspired Generative AI</title>
  <meta content="Biological inspired generative ai project from Carnegie Mellon University" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/logo.png " rel="icon">
  <link href=" " rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <link href="assets/css/style.css" rel="stylesheet">

</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <!-- <button type="button" class="mobile-nav-toggle d-xl-none"><i class="bi bi-list mobile-nav-toggle"></i></button> -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>
  <!-- ======= Header ======= -->
  <header id="header" class="d-flex flex-column justify-content-center">

    <nav id="navbar" class="navbar nav-menu">
      <ul>
        <li><a href="#home" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
        <li><a href="#about" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>About</span></a></li>
        <li><a href="#moca" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Prototype Memory</span></a></li>
        <li><a href="#surfgen" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Surface Generation</span></a></li>
        <li><a href="#resume" class="nav-link scrollto"><i class="bx bx-server"></i> <span>Shape Bias</span></a></li>
        <li><a href="#portfolio" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>On Going Projects</span></a></li>
        <li><a href="#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
      </ul>
    </nav><!-- .nav-menu -->

  </header><!-- End Header -->

  <!-- ======= home Section ======= -->
  <section id="home" class="d-flex flex-column justify-content-center">
    <div class="container" data-aos="zoom-out" data-aos-delay="100">
      <h1>Biological Inspired Generative AI</h1>
      <p>Build Next-Gen Generative AI models with <span class="typed" data-typed-items="Neuro-Symbolic Architectures, Hierarchical Compositional Graphs, Symbolic Prototype Primitives, Spherical Harmonic Surface Basis, Efficient Shape-based Coding, and more!"></span></p>
      <div class="social-links">
        <a href="https://www.linkedin.com/in/khalid-elgamely-874470242/" class="twitter"><i class="bx bxl-twitter"></i></a>
        <a href="https://www.linkedin.com/in/khalid-elgamely-874470242/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        <a href="https://github.com/biological-inspired-generative-ai" class="github"><i class="bx bxl-github"></i></a>
      </div>
      <div>
        <br>
      <p>Carnegie Mellon University 
        <br> 
        Computer Science Department
        <br> 
        Center For Neural Basis of Cognition
        <br> 
        Lee Laboratory for Biological and Machine Intelligence Research
      </p>
      </div>
    
    </div>
  </section><!-- End home -->

  <main id="main">

    <!-- ======= About Section ======= -->
    <section id="about" class="about resume">
      <div class="container" data-aos="fade-up">

        <div class="section-title">
          <h2>About</h2>
          <p>Generative AI has been the forefront of recent advancement in artificial intelligence ranging from image synthesis, 3D scene scene rendering and langauge models. However, leveraging biological inspiration to improve current limitation of the model remains difficult but beneficial. We aim to develop a framework that utilizes a range of biological findings, including efficient coding, compositionality, surface sphercial harmonics, and so on, to robustly improve the computer vision system. By incorporating the sparse symbolic code into the distributed networks, we aim to build Neuro-Synboligc Generative AI with greater efficiency, better robustness as well as more interpretablity. </p>  
        </div>

        <div class="row">
          <div class="col-lg-6">
            <h3 class="resume-title">Proposal</h3>
            <div class="resume-item pb-0">
              <!-- <h4>Goals</h4> -->
              <p>The world is made up of geometric primitives and their compositions. Humans perceive the world via constructing their generative internal models using various kinds of compositional symbolic parts. These parts form flexible graphs representing structural code that follows the efficient coding principle. Our brains then utilize this structural symbolic code to synthesize our internal generative view of the world, including shape, texture, surface, lighting, etc. This generated internal prediction is then matched with the real world’s stimulus to provide robust and generalizable visual understanding. We aim to equip the next-generation Generative AI with greater efficiency, robustness and interpretability through a sets of new ideas, including: </p>
              <ul>
                <li>Genealized Neuro-Symbolic Architecture</li>
                <li>Hierarchical Compositional Graphs</li>
                <li>Symbolic Prototype Primitives Memory</li>
                <li>Spherical Harmonic Surface Basis</li>
                <li>Efficient Shape-based Coding</li>
              </ul>
            </div>

          
          </div>


          <div class="col-lg-6">
            <h3 class="resume-title">Progress</h3>
            <div class="resume-item">
              <h4>Flexible Compositional "Geons" Learning</h4>
              <p> <em>Extract Generative Symbolic Knowledge Graphs by applying Biological Constraints</em>
              </p>
               <h5> Work in Progress - 2023 </h5>
            </div>
            <div class="resume-item">
              <h4>EFFICIENT CODING FOR Structural COMPOSITIONAL Generation</h4>
              <p><em>Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity</em>
              </p>
               <h5> Submission under review - 2023 </h5>
            </div>
            <div class="resume-item">
              <h4>Symbolic Prototype Memory For Few Shot Image Synthesis</h4>
              <p><em>MoCA: Prototype memory and attention mechanisms for few shot image generation</em>
              </p>
               <h5> ICLR - 2022 </h5>
            </div>
            <div class="resume-item">
              <h4>3D Shape Synthesis with explicit surface guidence</h4>
              <p><em>SurfGen: Adversarial 3D Shape Synthesis with Explicit Surface Discriminators</em>
              </p>
               <h5> ICCV - 2021 </h5>
            </div>

            
          </div>
        </div>

      </div>
    </section><!-- End About Section -->
    
    <!-- ======= MoCa Section ======= -->
    <section id="moca" class="project section-bg">
      <div class="container" data-aos="fade-up">

        <div class="section-title">
          <h2>Prototype Memory</h2>
          <br>
          <!-- <b>This is a professional skill set based on my work experience and acquired knowledge.</b> -->
          <p>Recent discoveries indicate that the neural codes in the superficial layers of the primary visual cortex (V1) of macaque monkeys are complex, diverse, and super-sparse. This leads us to ponder the computational advantages and functional role of these “grandmother cells." Here, we propose that such cells can serve as prototype memory priors that bias and shape the distributed feature processing during the image generation process in the brain. These memory prototypes are learned by momentum online clustering and are utilized through a memory-based attention operation. Integrating this mechanism, we propose <b>Memory Concept Attention (MoCA) </b> to improve few-shot image generation quality. We show that having a prototype memory with attention mechanisms can improve image synthesis quality, learn interpretable visual concept clusters, and improve the robustness of the model. Our results demonstrate the feasibility of the idea that these super-sparse complex feature detectors can serve as prototype memory priors for modulating the image synthesis processes in the visual system</p>
        </div>

        <div class="row">
          <div class="col-lg-6">
            <img src="assets/img/moca_1.png" class="img-fluid" alt="">
          </div>
          <div class="col-lg-6">
            <img src="assets/img/moca_parts.png" class="img-fluid" alt="">
          </div>
        </div>
        <br>
        <div class="section-title">

          <p>Performance and Visualizing Prototype Cluster Semantics in MoCA. We use MoCA-FastGAN model trained on
            MSCOCO-300 dataset for visualization. Each row is a generated image. We
            compute the cluster assignment for each hypercolumn in the layer where MoCA was installed and
            highlight the receptive fields of hypercolumns with white bounding boxes. We further group the
            visualization of the receptive fields by clusters (columns). For example, for column "Cluster 0", all
            white bounding boxes are the receptive fields of the hyper-columns that are modulated via Cluster 0’s
            prototypes. We observe that different clusters have different semantics since their prototypes tends to
            modulate different semantic regions of the images (See discussion in Section 4.3).</p>
          <br>
          <p>In this paper, we introduced a module called MoCA, which can be inserted into any layer of a
            hierarchical neural network such as a GAN to improve image synthesis. MoCA caches part prototype
            memories over time, dynamically updated using a momentum encoder, and has the ability to modulate
            the continuous response of intermediate layers via an attention mechanism. In contrast to earlier
            memory bank studies which stored representation of the entire images as prior in the latent space for
            object recognition, the prototypes in MoCA are remembered parts and sub-parts of objects, that can
            be extracted at every level of the hierarchy, and flexibly composed for image synthesis. Our work was
            inspired by the discovery of a diverse set of highly selective complex feature detectors in V1, which
            correspond to the prototype cells in MoCA. The selection of different prototype clusters via semantic
            cells could correspond to switching circuits mediated by inhibitory neurons. While we do not claim
            that there is any serious correspondence between our model and neural mechanisms or circuits, the
            effectiveness of MoCA might still provide some insights to the roles of these <b>"grandmother neurons"</b>
            at a functional level.</p> 
            <br>
            <p>Checkout our <a href="">project page</a> for more details!</p>
        
          </div>

      


      </div>
    </section><!-- End Skills Section -->
        <!-- ======= MoCa Section ======= -->
        <section id="surfgen" class="project section-bg">
          <div class="container" data-aos="fade-up">
    
            <div class="section-title">
              <h2>Surface Generation</h2>
              <br>
              <!-- <b>This is a professional skill set based on my work experience and acquired knowledge.</b> -->
              <p>Recent advances in deep generative models have led to
                immense progress in 3D shape synthesis. While existing
                models are able to synthesize shapes represented as voxels,
                point-clouds, or implicit functions, these methods only indirectly enforce the plausibility of the final 3D shape surface.
                Here we present a 3D shape synthesis framework (SurfGen)
                that directly applies adversarial training to the object surface. Our approach uses a differentiable spherical projection layer to capture and represent the explicit zero isosurface of an implicit 3D generator as functions defined on the
                unit sphere. By processing the spherical representation of
                3D object surfaces with a spherical CNN in an adversarial
                setting, our generator can better learn the statistics of natural shape surfaces. We evaluate our model on large-scale
                shape datasets, and demonstrate that the end-to-end trained
                model is capable of generating high fidelity 3D shapes with
                diverse topology. </p>


            </div>
    
            <div class="row">
              <div class="col-lg-6">
                <img src="assets/img/surfgen.png" class="img-fluid" alt="">
              </div>
              <div class="col-lg-6">
                <img src="assets/img/surfgen_2.png" class="img-fluid" alt="">
              </div>
            </div>
            <br>
            <div class="section-title">
    
              <p>Any continuous function on the surface of a sphere can be approximated as a sum of spherical harmonic basis functions. Spherical harmonics act as an orthogonal basis set.
                The spherical harmonic coefficients fully characterize the function. So they provide a compact representation of surfaces.
                Lower frequency spherical harmonics capture coarse, global aspects of a surface. Higher frequencies add finer details. This creates a multi-scale representation.
                Spherical harmonics can smoothly interpolate between surface samples. This helps fill in missing data.
                Rotating a spherical harmonic representation just involves rotating the basis functions, not re-computing coefficients. This makes alignments easy.
                Efficient algorithms exist to transform between 3D surfaces and their spherical harmonic coefficients.</p>
              <br>
              <p>In this paper, we have introduced a novel shape synthesis method that allows a discriminator to focus directly on
                the surface on a generated shape. Our method is capable
                of generating diverse high quality shapes with complex geometry. Our model has diverse downstream applications as
                part of a larger 3D synthesis pipeline. We hope our work
                will inspire future research in 3D shape synthesis.</p> 
                <br>
                <p>Checkout our <a href="">project page</a> for more details!</p>
            
              </div>
    
          
            <!-- <div class="row skills-content">
              
              <div class="col-lg-6">
                
                <div class="progress">
                  <span class="skill">Redux Toolkit <i class="val">90%</i></span>
                  <div class="progress-bar-wrap">
                    <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100">
                    </div>
                  </div>
                </div>
    
                <div class="progress">
                  <span class="skill">Javascript<i class="val">85%</i></span>
                  <div class="progress-bar-wrap">
                    <div class="progress-bar" role="progressbar" aria-valuenow="85" aria-valuemin="0" aria-valuemax="100">
                    </div>
                  </div>
                </div>
    
                <div class="progress">
                  <span class="skill">HTML/CSS <i class="val">90%</i></span>
                  <div class="progress-bar-wrap">
                    <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100">
                    </div>
                  </div>
                </div>
    
              </div>
    
              <div class="col-lg-6">
    
                <div class="progress">
                  <span class="skill">ReactJS <i class="val">90%</i></span>
                  <div class="progress-bar-wrap">
                    <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100">
                    </div>
                  </div>
                </div>
    
                <div class="progress">
                  <span class="skill">Material ui <i class="val">80%</i></span>
                  <div class="progress-bar-wrap">
                    <div class="progress-bar" role="progressbar" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100">
                    </div>
                  </div>
                </div>
    
              </div>
    
            </div> -->
    
          </div>
        </section><!-- End Skills Section -->
    
    <!-- ======= Resume Section ======= -->
    <section id="resume" class="resume">
      <div class="container" data-aos="fade-up">

        <div class="section-title">
          <h2>Efficient Coding for Compositional Vision</h2>
          <br>
          <!-- <b>This is a professional skill set based on my work experience and acquired knowledge.</b> -->
          <p>
            Current deep-learning models for object recognition are known to be heavily biased
toward texture. In contrast, human visual systems are known to be biased toward
shape and structure. What could be the design principles in human visual systems
that led to this difference? How could we introduce more shape bias into the deep
learning models? In this paper, we report that sparse coding, a ubiquitous principle
in the brain, can in itself introduce shape bias into the network. We found that
enforcing the sparse coding constraint using a non-differential Top-K operation
can lead to the emergence of structural encoding in neurons in convolutional neural
networks, resulting in a smooth decomposition of objects into parts and subparts and
endowing the networks with shape bias. We demonstrated this emergence of shape
bias and its functional benefits for different network structures with various datasets.
For object recognition convolutional neural networks, the shape bias leads to greater
robustness against style and pattern change distraction. For the image synthesis
generative adversary networks, the emerged shape bias leads to more coherent and
decomposable structures in the synthesized images. Ablation studies suggest that
sparse codes tend to encode structures, whereas the more distributed codes tend to
favor texture. 
          </p></div>

          <div class="row">
            <div class="col-lg-6">
              <img src="assets/img/ShapeBias-ts-1.png" class="img-fluid" alt="">
            </div>
            <div class="col-lg-6">
              <img src="assets/img/ShapeBias-ts-2.png" class="img-fluid" alt="">
            </div>
          </div>

          <p>Current deep-learning models for object recognition are known to be heavily biased
            toward texture. In contrast, human visual systems are known to be biased toward
            shape and structure. What could be the design principles in human visual systems
            that led to this difference? How could we introduce more shape bias into the deep
            learning models? In this paper, we report that sparse coding, a ubiquitous principle
            in the brain, can in itself introduce shape bias into the network. We found that
            enforcing the sparse coding constraint using a non-differential Top-K operation
            can lead to the emergence of structural encoding in neurons in convolutional neural
            networks, resulting in a smooth decomposition of objects into parts and subparts and
            endowing the networks with shape bias. We demonstrated this emergence of shape
            bias and its functional benefits for different network structures with various datasets.
            For object recognition convolutional neural networks, the shape bias leads to greater
            robustness against style and pattern change distraction. For the image synthesis
            generative adversary networks, the emerged shape bias leads to more coherent and
            decomposable structures in the synthesized images. Ablation studies suggest that
            sparse codes tend to encode structures, whereas the more distributed codes tend to
            favor texture. </p>

        <!-- <div class="row">
          <div class="col-lg-6">
            <h3 class="resume-title">Summary</h3>
            <div class="resume-item pb-0">
              <h4>Khaled Elgamely</h4>
              <p><em>Hi Everyone, I am Khaled Elgamely from cairo , Egypt I am a junior Front End Developer.
                Building resposive website, I am experienced with Front-end Web development and design using ReactJS, HTML, and CSS,
                My interests also lie in solving problems related to data structures and algorithms.</em></p>
              <ul>
                <li>Cairo, Egypt</li>
                <li>+201552600743</li>
                <li>kahledelgamely50@gmail.com</li>
              </ul>
            </div>

            <h3 class="resume-title">Education</h3>
            <div class="resume-item">
              <h4>Bachelor of clinical, pharmacy</h4>
              <h5>2014 - 2019</h5>
              <p><em>Clinical Pharmacy</em></p>
            </div>
          </div>


          <div class="col-lg-6">
            <h3 class="resume-title">Certificates</h3>
            <div class="resume-item">
              <h4>Front-end web development professional nanodegree</h4>
              <h5>May 2022 - July 2022</h5>
              <p><em> fwdEgypt, Udacity </em></p>
            </div>
            <div class="resume-item">
              <h4>Front-End Web Development with React</h4>
              <h5>Mar 2022 - Apr 2022</h5>
              <p><em> Coursera </em></p>
            </div>
            <div class="resume-item">
              <h4>HTML, CSS, and Javascript for Web Developers</h4>
              <h5>Sep 2021 - Oct 2021</h5>
              <p><em> Coursera </em></p>
            </div>

            
          </div>
        </div> -->
    </section><!-- End Resume Section -->

    <!-- ======= Portfolio Section ======= -->
    <section id="portfolio" class="portfolio section-bg">
      <div class="container" data-aos="fade-up">

        <div class="section-title">
          <h2>FLEXIBLE COMPOSITIONAL "GEONS" LEARNING</h2>
        </div>

        
      </div>
    </section>

   <!-- ======= Contact Section ======= -->
   

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <h4>Biological Inspired AI Project Page</h4>
      <p>CMU Computer Science Department & Center for Neural Basis of Cognition</p>
     
      <div class="social-links">
        <a  href="https://github.com/khaledelgamely"  class="twitter"><i class="bx bxl-twitter"></i></a>
        <a  href="https://github.com/khaledelgamely"  class="github"><i class="bx bxl-github"></i></a>
        <a href="https://www.linkedin.com/in/khalid-elgamely-874470242/"class="linkedin"><i class="bx bxl-linkedin"></i></a>
      </div>
      <div class="copyright">
        <strong><span>Thank you for stopping by.</span></strong>
      </div>
      <div class="credits">
      </div>
    </div>
  </footer><!-- End Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/js/main.js"></script>

</body>
</html>
